#########################################################################################################################################
# Object Alignment
#########################################################################################################################################

Problem: We are occasionally matching the wrong edges of the object together.
Solution: 

Problems: New method for detecting if an object crosses the main view edge does introduced unexpected problem if the object crosses off of the image on the opposite side.
Solution: this method may be difficult to solve. We need some method of determining whether the object passes off of the portion of the image corresponding to the direction of the side view. However, the object location in the main view can
diverge from that direction by a significant margin. I'll have to think on it. 

(COMPLETED) Problem: Ran into an error when the object was detected in the corner of the image. This meant that when the neighborhood was detectec, it tried to grab somewhere outside of the image coordinate system and crashed. 
Solution: Added in error checking code. 

Problem: By August we need to fix: limitations on when the object is picked up and aligned. Utilize fifth camera to remove parallel degeneracy. Write journal paper by end of August. 
We need to have the line alignment working most of the time on objects when the object is in the correct field of view with sufficient overlap between images. If the algorithm fails 
in corner cases, that is fine but it needs to work well in the ideal cases.  

Problem: We need to develop a library of test videos and determine a metric for the quality of our algorithm. 
Solution: 

Problem: The seam detection seems off. I'm going to try and fix it. 
Solution: I replaced the old method with a new one which simply calculates the edges of the main view image as they will show up in the side view coordinate system. 


Problem: Our method for identifying the and finding the tool currently relies on outdated assumptions which do not serve well in the bean drop case. As such the line alignment needs an improved object identification, tracking and segmentation method before it can be applied to these more general cases. 
Solution: Current Proposed solution is that we use a Mixture of Gaussians background subtractor method to identify the probable location of the object. Then we use some form of spatially based image segmentation method to identify
the exact shape of the object. Then finally we give the line alignment method the location of the edges of the object. This will need implementation and development and may be too computationally expensive for our application.  

(COMPLETED))Problem: The 8 point method for computing the fundamental matrix from feature matches in an uncalibrated camera is degenerate if all the points
are coplanar. Our calibration method for homographies require an approximately planar calibration pattern, so either we have a bad fundamental matrix
or a bad homography. 
Solution: We calibrate the camera array for both intrinsic and extrinsic parameters before placing the array in the surgical area. From these parameters, we can calculate the Fundamental matrix.

Problem: In the bean drop sample data sets, The matching is giving bad matches for an unknown reason. 
Solution: Try Rotating the images so that they all share the same set of axes before calculating fundamental matrix. Identify the cause of the bad matches. First look at the epipolar lines and see what is going on with them. Second, double check to ensure the code is functioning as desired. After that adjust as needed. The epipolar lines look strange for some reason. I still haven't been able to pin down what is going on here, but their behavior is not as expected. The end 
result was determining that the problem was due to us using a degenerate case of the 8 point fundamental matrix estimation algorithm. 

(COMPLETED) Problem: When feature points lie too closely together on a line, the resulting homography can be a poor match for the desired outcome. 
Solution:  We solved this by choosing an arbitrary location along the line to use as the matched points. This allows us to ensure there is sufficient 
distance between the points. However, It fails in the 2 edge case because the incorrect homography is calculated if some of the points lie after the lines 
have crossed over each other. The final solution I have decided on for now is to simply shift the points to encourage them to be further from each other and 
still within the viewed object. This may need revisiting with a more sophisticated method in the future. 

Problem: If the object happens to fall close to parallel to the epipolar lines being used, we end up with a bad result. 
Solution: This is an interesting one. The angle of the epipolar lines change depending on the point used. We may be able to choose which point to use 
in order to minimize the instability of the estimate. I must look into what scene results can cause an epipolar line to be parallel to an object line.
The lines will be parallel if the object itself lies on the plane created by intersecting the base line with the ray to the object. We note that in the case
where the camera rotation is purely around the depth axis for the camera, then all of the epipolar lines will be parallel and we will have an object orientation that will always result in poor matching 

Problem: Objects aren't corrected across secondary to secondary boundaries. 
Solution: Applying line alignment to all side views that have the located image should align the object across secondary boundaries. This needs to be tested. 

Problem: When the stitching fails, it causes jump discontinuities in the video that might be disconcerting to a surgeon. 
Solution: Unknown. Perhaps we need to find a way to implement temporal continuity constraints. 

Problem: In the bean drop case, the hole in the cup keeps being detected as an object point rather than the tool itself. 
solution: Update method for finding tool. We have also gathered some data sets with the cup further away from the seam line. This is just a temporary patch. 

Problem: In the bean drop case, object segmentation has a hard time determining what is tool and what is background (cup, writing on paper, bean, etc.)
Solution: We may need some sort of improved object segmentation method. I need to talk to Zhanpeng about how this is currently done. 

Problem: There are occasional instances of massive discolorations of the image. This usually happens during failed alignments. 
Solution: We need to identify the cause. I am guessing that it may be related to the method of filling in gaps left by moved objects.

Problem: When an object crosses multiple different seams, or is only half seen in the image, it will not be considered for object alignment. 
Solution: Use one edge alignment when the object is only half in the image. Perhaps use the corner of the object as a good feature point? We also need to 
fix the problem that we do not appear to check all possible seams for objects, but only a subset of them. Actually, Crossing multiple seams should not be an issue. If
the object is seen in multiple different side views, then applying the line alignment from those side views to the main views should map all views of the object to a consistent
coordinate system. 

Problem: The space where the object used to be is very clearly visible. 
Solution: store previous frame and fill in details from that. Or simply wait to draw updated image until the correct object location has been
determined so that the pixels for the incorrect object location wont be updated.

Problem: Occasionally, the object is disappearing when it is detected across the seam line but a linear match is not found. 
Solution: It seems like this might be resulting from a bug in the code causing a transformation to be applied without a valid transformation being calculated. 
This should be simple debugging. 

(COMPLETED) Problem: Alignment fails when faced with a purely vertical line. 
Solution: Adjust method for calculating line intersections to be robust to vertical lines. 



cap = cv2.VideoCapture("udpsrc port=5600 caps=\"application/x-rtp, format=(string)I420, width=(int)1280, height=(int)720, pixel-aspect-ratio=(fraction)1/1, interlace-mode=(string)progressive, colorimetry=(string)bt709, framerate=(fraction)25/1\" ! rtph264depay ! decodebin ! appsink")







#############################################################################################################################################
# General Stitching
#############################################################################################################################################
(COMPLETED)Problem: When stitching, some discolorations happen. I suspect this is because the mask that is used for blending isn't uniform across color.
Solution: Rather than creating the mask from a basic command of (image > 0) ensure to run some method of checking if any of the pixels are 
greater than 0. 

Problem: Stitcher will fail if incoming images do not have identical shape.
Solution: change input method for stitcher or only rotate images within the faststitch program. 



#############################################################################################################################################
# Lazy Stitching
#############################################################################################################################################

Problem: Lazy Stitching causes layering of images to shift, creating unreliable secondary to secondary object boundaries. 
Solution: I'll talk to Zhanpeng about what is going on here and see if we can figure something out. 


#############################################################################################################################################
# Preparations
#############################################################################################################################################

1. collect references (everything that are relevant), create a reference database and for each paper you read and feel relevant, write a 1-2 sentence summary/comment and put it in the "note" field of your reference database. In the future, when you write related work section, these notes will be handy.
	
	I have a Mendeley collection of relevant papers I have found. I have not yet annotated them. 

2. collect all public domain software (OpenCV, github, matlab, matlab central, and other places e.g. http://homepages.cae.wisc.edu/~ece539/software/index.html that may be useful/relevant
	
	I have a collection of python scripts and openCV installed on my computer to perform this task. 

3. collect and annotate the data you are to work with and if possible some test data existing public domain software may be using to demonstrate their performance.

4. decide performance metric (to determine which method is better) and cost metric (if applicable to determine which method is more efficient and practical)
	
	I'm still working to figure out a performance metric for this method. Cost is defined by the amount of time it takes to perform the method, the removal of discontinuities
	along seam lines between images and the reliability of the method performing as expected. 

5. apply public domain software or any preliminary program you developed (see #2) to the data you prepared (#3) and apply the criteria in #4 to derive a baseline result.
	



Image Stitching Software:
Hugin
Autostitch


Video Stitching software:
SkyStitch